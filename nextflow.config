/*
 * -------------------------------------------------
 *  nf-core/nanoclust Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {

  // Boilerplate options
  outdir = './results'
  demultiplex = false
  demultiplex_porechop = false
  guppy_barcoder = false
  multiqc = false
  kit = "unknown"
  clusterOpts = ''

  // Canu consensus correction options
  stopOnLowCoverage = 1
  minInputCoverage = 2
  minReadLength = 500
  minOverlapLength = 200 
  useGrid = false
  
  // UMAP Clustering and polishing parameters
  throughput = 'standard'
  umap_set_size = 100000
  umap_n_neighbors = 15
  umap_min_dist = 0.1
  cluster_sel_epsilon = 0.5
  min_cluster_size = 50
  min_samples = "'n'"
  polishing_reads = 100
  min_read_length = 1400
  max_read_length = 1700
  avg_amplicon_size = "1.5k"

  // Classification parameters
  remove_unclassified = false
  db = false
  db2 = false
  tax = false
  classification = 'blast'
  accession = false
  reclassifyOnFail = false

  // Report options
  generateReports = false
  experimentInfo = "$launchDir/experiment_info.xlsx"

  //Other parameters
  name = false
  multiqc_config = "$baseDir/assets/multiqc_config.yaml"
  email = false
  email_on_fail = false
  maxMultiqcEmailFileSize = 25.MB
  plaintext_email = false
  monochrome_logs = false
  help = false
  tracedir = "${params.outdir}/pipeline_info"
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
  onGridIon = false
}

manifest {
  name = 'genomicsITER/nanoclust'
  author = 'Hector Rodriguez-Perez, Laura Ciuffreda'
  homePage = 'https://github.com/nf-core/nanoclust'
  description = 'De novo clustering and consensus building for ONT 16S sequencing data'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = '1.0dev'
}

executor {
  $sge {
    queueSize = 100
  }
}

process {
    errorStrategy = 'ignore'
    withName: demultiplex { cpus = 4 }
    withName: guppy_barcoder { 
      cpus = 4 
      memory = 4.GB
    }
    withName: QC { 
      cpus = 2 
      errorStrategy = 'ignore' }
    withName: remove_unclassified {
      cpus = 1
    }
    withName: kmer_freqs { 
      cpus = 4
      memory = { 4.GB * task.attempt }
      time = { 1.hour * task.attempt }
      errorStrategy = { task.exitStatus in 137..140 ? 'retry': 'ignore' }
      maxRetries = 3
    }
    withName: read_clustering {
      errorStrategy = { task.exitStatus in 137..140 ? 'retry': 'ignore' }
    }
    withName: split_by_cluster { cpus = 1 }
    withName: read_correction { 
      cpus = 1
      memory = { 4.GB * task.attempt }
      time = { 1.hour * task.attempt }
      errorStrategy = { task.exitStatus in 137..140 ? 'retry': 'ignore' }
      maxRetries = 3
    }
    withName: draft_selection { 
      cpus = 4 
      errorStrategy = { task.exitStatus == 73 ? 'ignore' : 'retry'}
    }
    withName: racon_pass { 
      cpus = 1
      memory = { 4.GB * task.attempt }
      time = { 1.hour * task.attempt }
      errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'ignore' }
      maxRetries = 3
    }
    withName: medaka_pass {
      cpus = 1
      memory = { 4.GB * task.attempt }
      time = { 1.hour * task.attempt }
      errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'ignore' }
      maxRetries = 3
    }
    withName: consensus_classification { cpus = 1 }
    withName: join_results { cpus = 1 }
    withName: get_abundances { cpus = 1 }
    withName: plot_abundances { cpus = 1 }
    withName: collect_metadata { cpus = 1 }
    withName: generate_reports { cpus = 1 }
    withName: output_documentation { cpus = 1 }
    withName: multiqc { cpus = 1 }
    withLabel: standard {
      cpus = 1
      memory = 36.GB
    }
    withLabel: high_sensitivity {
      cpus = 1
      memory = 40.GB
    }
    withLabel: low_resource {
      cpus = 1
      memory = 10.GB
    }
}

profiles {
  test { includeConfig 'conf/test.config' }
  conda { 
    process {
      withName: demultiplex { conda = "$baseDir/conda_envs/demultiplex/environment.yml" }
      withName: demultiplex_porechop { conda = "$baseDir/conda_envs/demultiplex_porechop/environment.yml" }
      withName: guppy_barcoder { conda = "$baseDir/conda_envs/qc_fastp/environment.yml" }
      withName: QC { conda = "$baseDir/conda_envs/qc_fastp/environment.yml" }
      withName: remove_unclassified { conda = "$baseDir/conda_envs/consensus_classification/environment.yml" }
      withName: subset_reads { conda = "$baseDir/conda_envs/qc_fastp/environment.yml" }
      withName: multiqc { conda = "$baseDir/conda_envs/qc_fastp/environment.yml" }
      withName: kmer_freqs { conda = "$baseDir/conda_envs/kmer_freqs/environment.yml" }
      withName: read_clustering { conda = "$baseDir/conda_envs/read_clustering/environment.yml" }
      withName: split_by_cluster { conda = "$baseDir/conda_envs/split_by_cluster/environment.yml" }
      withName: read_correction { conda = "$baseDir/conda_envs/read_correction/environment.yml" }
      withName: draft_selection { conda = "$baseDir/conda_envs/draft_selection/environment.yml" }
      withName: racon_pass { conda = "$baseDir/conda_envs/racon_pass/environment.yml" }
      withName: medaka_pass { conda = "$baseDir/conda_envs/medaka_pass/environment.yml" }
      withName: consensus_classification { conda = "$baseDir/conda_envs/consensus_classification/environment.yml" }
      withName: collect_metadata { conda = "$baseDir/conda_envs/generate_reports/environment.yml" }
      withName: get_abundances { conda = "$baseDir/conda_envs/cluster_plot_pool/environment.yml" }
      withName: plot_abundances { conda = "$baseDir/conda_envs/cluster_plot_pool/environment.yml" }
      withName: generate_reports { conda = "$baseDir/conda_envs/generate_reports/environment.yml" }
      withName: output_documentation { conda = "$baseDir/conda_envs/output_documentation/environment.yml" }
    }
  }
  docker { 
    docker.enabled = true 
    //process.container = 'nf-core/nanoclust:latest'
    process {
      withName: demultiplex { container = 'hecrp/nanoclust-demultiplex' }
      withName: demultiplex_porechop { container = 'hecrp/nanoclust-demultiplex_porechop' }
      withName: QC { container = 'hecrp/nanoclust-qc' }
      withName: fastqc { container = 'hecrp/nanoclust-fastqc' }
      withName: multiqc { container = 'hecrp/nanoclust-qc' }
      withName: kmer_freqs { container = 'hecrp/nanoclust-kmer_freqs' }
      withName: read_clustering { container = 'hecrp/nanoclust-read_clustering' }
      withName: split_by_cluster { container = 'hecrp/nanoclust-split_by_cluster' }
      withName: read_correction { container = 'hecrp/nanoclust-read_correction' }
      withName: draft_selection { container = 'hecrp/nanoclust-draft_selection' }
      withName: racon_pass { container = 'hecrp/nanoclust-racon_pass' }
      withName: medaka_pass { container = 'hecrp/nanoclust-medaka_pass' }
      withName: consensus_classification { container = 'hecrp/nanoclust-consensus_classification'
                                           docker.temp = "$baseDir/" }
      withName: get_abundances { container = 'hecrp/nanoclust-plot_abundances' }
      withName: plot_abundances { container = 'hecrp/nanoclust-plot_abundances' }
      withName: output_documentation { container = 'hecrp/nanoclust-output_documentation' }
    }
  }
  local {
    process.executor = 'local'
  }
  sge {
    process {
      executor = 'sge'
      module = 'apps/python/conda'
      beforeScript = 'source ~/.bashrc'
      penv = 'smp'
      clusterOptions = "${params.clusterOpts}"
      withLabel: standard {
        clusterOptions = "${params.clusterOpts} -l rmem=36G'"
      }
      withLabel: high_sensitivity {
        clusterOptions = "${params.clusterOpts} -l rmem=40G"
      }
      withLabel: low_resource {
        clusterOptions = "${params.clusterOpts} -l rmem=10G"
      }
    }
  }
  low_resource {
    params {
      umap_set_size=50000
      throughput = 'low'
    }
  }
  high_sensitivity {
    params {
      umap_set_size=200000
      min_cluster_size=15
      throughput = 'high'
    }
  }
}


// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Avoid this error:
// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351, once this is established and works well, nextflow might implement this behavior as new default.
docker.runOptions = '-u \$(id -u):\$(id -g)'


// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
